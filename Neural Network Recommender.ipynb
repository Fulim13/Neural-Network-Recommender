{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50f66da4-c023-4f4e-a837-9becfe154118",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f7df09-631e-47d4-9b87-68a8f73f1a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ec4bb8-22e2-4876-8954-32747e5156f2",
   "metadata": {},
   "source": [
    "# Step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587c558e-5006-415a-a546-a3d09a530fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ratings.csv file\n",
    "df = pd.read_csv(\"ratings.csv\")\n",
    "max = df['userId'].max()\n",
    "min =df['userId'].min()\n",
    "\n",
    "# Load the movies.csv file\n",
    "movies_df = pd.read_csv(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66d444b-4c0c-4c18-8e78-1924fe420cc7",
   "metadata": {},
   "source": [
    "# Step 3: Define Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af53eec7-b473-427d-97c9-a32ee454c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, users, movies, ratings):\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.ratings = ratings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        users = self.users[item]\n",
    "        movies = self.movies[item]\n",
    "        ratings = self.ratings[item]\n",
    "\n",
    "        return {\n",
    "            \"users\": torch.tensor(users, dtype=torch.long),\n",
    "            \"movies\": torch.tensor(movies, dtype=torch.long),\n",
    "            \"ratings\": torch.tensor(ratings, dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f9b1b-0453-4110-a0ec-8934bbad097b",
   "metadata": {},
   "source": [
    "# Step 4: Define Neural Network CF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e05fb-215c-48c8-ba4c-9955a059d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationSystemModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users,\n",
    "        num_movies,\n",
    "        embedding_size=256,\n",
    "        hidden_dim=256,\n",
    "        dropout_rate=0.2,\n",
    "    ):\n",
    "        super(RecommendationSystemModel, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Embedding layers\n",
    "        self.user_embedding = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.embedding_size\n",
    "        )\n",
    "        self.movie_embedding = nn.Embedding(\n",
    "            num_embeddings=self.num_movies, embedding_dim=self.embedding_size\n",
    "        )\n",
    "\n",
    "        # Hidden layers\n",
    "        self.fc1 = nn.Linear(2 * self.embedding_size, self.hidden_dim)\n",
    "        self.fc2 = nn.Linear(self.hidden_dim, 1)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, users, movies):\n",
    "        # Embeddings\n",
    "        user_embedded = self.user_embedding(users)\n",
    "        movie_embedded = self.movie_embedding(movies)\n",
    "\n",
    "        # Concatenate user and movie embeddings\n",
    "        combined = torch.cat([user_embedded, movie_embedded], dim=1)\n",
    "\n",
    "        # Pass through hidden layers with ReLU activation and dropout\n",
    "        x = self.relu(self.fc1(combined))\n",
    "        x = self.dropout(x)\n",
    "        output = self.fc2(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d851ef-a8e2-4516-9da2-2e9d42ae17da",
   "metadata": {},
   "source": [
    "# Step 5: Data Preprocessing and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cde2a6-f21b-4a12-a4ff-807b32b4e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_user = preprocessing.LabelEncoder()\n",
    "le_movie = preprocessing.LabelEncoder()\n",
    "df.userId = le_user.fit_transform(df.userId.values)\n",
    "df.movieId = le_movie.fit_transform(df.movieId.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f30e8-f852-4db5-bb3e-fa11e4f22fb8",
   "metadata": {},
   "source": [
    "# Step 6: Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a03a3-95c1-4998-a696-b545719e65ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = model_selection.train_test_split(\n",
    "    df, test_size=0.1, random_state=3, stratify=df.rating.values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be8feea-9131-4684-ba48-f4acf1c4844b",
   "metadata": {},
   "source": [
    "# Step 7: Creating Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5865db15-0488-4fa6-971c-d547390a242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MovieLensDataset(\n",
    "    users=df_train.userId.values,\n",
    "    movies=df_train.movieId.values,\n",
    "    ratings=df_train.rating.values,\n",
    ")\n",
    "\n",
    "valid_dataset = MovieLensDataset(\n",
    "    users=df_val.userId.values,\n",
    "    movies=df_val.movieId.values,\n",
    "    ratings=df_val.rating.values,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718a4223-d7bd-406b-9c72-17b612ccf9ac",
   "metadata": {},
   "source": [
    "# Step 8: Initializing Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa15ca7-4232-4fdc-9ed6-190299ca5a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec98aac-c115-428d-b5e8-a1f3db2ccdda",
   "metadata": {},
   "source": [
    "# Step 9: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb00e1-cac2-4822-ba3c-a86f77808a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "recommendation_model = RecommendationSystemModel(\n",
    "    num_users=len(le_user.classes_), \n",
    "    num_movies=len(le_movie.classes_),\n",
    "    embedding_size=128,\n",
    "    hidden_dim=256,\n",
    "    dropout_rate=0.1,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(recommendation_model.parameters(), lr=1e-3)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "# Function to log progress\n",
    "def log_progress(epoch, step, total_loss, log_progress_step, data_size, losses):\n",
    "    avg_loss = total_loss / log_progress_step\n",
    "    sys.stderr.write(\n",
    "        f\"\\r{epoch+1:02d}/{EPOCHS:02d} | Step: {step}/{data_size} | Avg Loss: {avg_loss:<6.9f}\"\n",
    "    )\n",
    "    sys.stderr.flush()\n",
    "    losses.append(avg_loss)\n",
    "\n",
    "total_loss = 0\n",
    "log_progress_step = 100\n",
    "losses = []\n",
    "train_dataset_size = len(train_dataset)\n",
    "print(f\"Training on {train_dataset_size} samples...\")\n",
    "\n",
    "recommendation_model.train()\n",
    "for e in range(EPOCHS):\n",
    "    step_count = 0  # Reset step count at the beginning of each epoch\n",
    "    for i, train_data in enumerate(train_loader):\n",
    "        output = recommendation_model(\n",
    "            train_data[\"users\"].to(device), train_data[\"movies\"].to(device)\n",
    "        )\n",
    "        # Reshape the model output to match the target's shape\n",
    "        output = output.squeeze()  # Removes the singleton dimension\n",
    "        ratings = (\n",
    "            train_data[\"ratings\"].to(torch.float32).to(device)\n",
    "        )  # Assuming ratings is already 1D\n",
    "        loss = loss_func(output, ratings)\n",
    "        total_loss += loss.sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Increment step count by the actual size of the batch\n",
    "        step_count += len(train_data[\"users\"])\n",
    "\n",
    "        # Check if it's time to log progress\n",
    "        if (\n",
    "            step_count % log_progress_step == 0 or i == len(train_loader) - 1\n",
    "        ):  # Log at the end of each epoch\n",
    "            log_progress(\n",
    "                e, step_count, total_loss, log_progress_step, train_dataset_size, losses\n",
    "            )\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cae346-ff6c-48b4-a42f-cc3e9eae41ca",
   "metadata": {},
   "source": [
    "# Step 10: Save the Model for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cbce3e-449a-4154-8d6f-32fd9482d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(recommendation_model.state_dict(), \"recommendation_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b889ddd7-83f9-439e-90b2-74b3ad8e44a9",
   "metadata": {},
   "source": [
    "# Step 11: Display Average Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0038bc-4c66-4341-9f39-2c25ad078ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639004c7-c4e9-4b2c-85dc-9bb195a3a9d6",
   "metadata": {},
   "source": [
    "# Step 12: Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455e1b68-d6c3-4fff-9edd-d23027dfdf93",
   "metadata": {},
   "source": [
    "## RMSE (Root Mean Square Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f56d6-0ccf-4065-b435-6747e06999c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "recommendation_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, valid_data in enumerate(val_loader):\n",
    "        output = recommendation_model(\n",
    "            valid_data[\"users\"].to(device), valid_data[\"movies\"].to(device)\n",
    "        )\n",
    "        y_pred.append(output.sum().item() / len(valid_data[\"users\"]))\n",
    "        ratings = valid_data[\"ratings\"]\n",
    "        y_true.append(ratings.sum().item() / len(valid_data[\"users\"]))\n",
    "\n",
    "rms = root_mean_squared_error(y_true, y_pred)\n",
    "print(f\"rmse: {rms:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1722c218-2a22-43ba-9f99-b341f38e2080",
   "metadata": {},
   "source": [
    "## Precision@k and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b8997-e106-412d-9a74-3a69a23bc173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall(user_ratings, k, threshold):\n",
    "    user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "    n_rel = sum(true_r >= threshold for _, true_r in user_ratings)\n",
    "    n_rec_k = sum(est >= threshold for est, _ in user_ratings[:k])\n",
    "    n_rel_and_rec_k = sum((true_r >= threshold) and (est >= threshold) for est, true_r in user_ratings[:k])\n",
    "\n",
    "    precision = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "    recall = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "    return precision, recall\n",
    "\n",
    "user_ratings_comparison = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for valid_data in val_loader:\n",
    "        users = valid_data[\"users\"].to(device)\n",
    "        movies = valid_data[\"movies\"].to(device)\n",
    "        ratings = valid_data[\"ratings\"].to(device)\n",
    "        output = recommendation_model(users, movies)\n",
    "\n",
    "        for user, pred, true in zip(users, output, ratings):\n",
    "            user_ratings_comparison[user.item()].append((pred[0].item(), true.item()))\n",
    "\n",
    "user_precisions = dict()\n",
    "user_based_recalls = dict()\n",
    "\n",
    "k = 50\n",
    "threshold = 3\n",
    "\n",
    "for user_id, user_ratings in user_ratings_comparison.items():\n",
    "    precision, recall = calculate_precision_recall(user_ratings, k, threshold)\n",
    "    user_precisions[user_id] = precision\n",
    "    user_based_recalls[user_id] = recall\n",
    "\n",
    "\n",
    "average_precision = sum(prec for prec in user_precisions.values()) / len(user_precisions)\n",
    "average_recall = sum(rec for rec in user_based_recalls.values()) / len(user_based_recalls)\n",
    "\n",
    "print(f\"precision @ {k}: {average_precision:.4f}\")\n",
    "print(f\"recall @ {k}: {average_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e97ec25-c4a9-4060-a906-cd793ebbbc14",
   "metadata": {},
   "source": [
    "# Step 13: Recommend Top 5 Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844034d8-af0f-4c25-bccc-a752128b0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_top_n_movies(n):\n",
    "    while True:\n",
    "        original_user_id = int(input(\"Enter a user ID: \"))\n",
    "        if original_user_id <= max and original_user_id >= min:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid user ID. Please try again.\")\n",
    "        \n",
    "    user_id = le_user.transform([original_user_id])[0]\n",
    "    \n",
    "    all_movie_ids = set(df.movieId.unique())\n",
    "    \n",
    "    seen_movie_ids = set(df[df.userId == user_id].movieId.unique())\n",
    "    \n",
    "    original_seen_movie_ids = le_movie.inverse_transform(list(seen_movie_ids))\n",
    "    \n",
    "    seen_movies = movies_df[movies_df['movieId'].isin(original_seen_movie_ids)]\n",
    "    \n",
    "    # Print the seen movies\n",
    "    print(\"Movies you've seen:\")\n",
    "    print(tabulate(seen_movies[['movieId', 'title']], headers='keys', tablefmt='psql', showindex=False))\n",
    "    \n",
    "    unseen_movie_ids = all_movie_ids - seen_movie_ids\n",
    "    unseen_movie_ids = list(unseen_movie_ids)\n",
    "    \n",
    "    users = [user_id] * len(unseen_movie_ids)\n",
    "    movies = unseen_movie_ids\n",
    "    ratings = [0] * len(unseen_movie_ids)  # dummy ratings\n",
    "    \n",
    "    dataset = MovieLensDataset(users, movies, ratings)\n",
    "    data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    recommendation_model.eval()\n",
    "    predicted_ratings = []\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            output = recommendation_model(data[\"users\"].to(device), data[\"movies\"].to(device))\n",
    "            predicted_ratings.extend(output.squeeze().tolist())\n",
    "    \n",
    "    movie_ratings = list(zip(unseen_movie_ids, predicted_ratings))\n",
    "    \n",
    "    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_n_movie_ids = []\n",
    "    top_n_movie_names = []\n",
    "    for movie_id, _ in movie_ratings:\n",
    "        if movie_id in movies_df.movieId.values:\n",
    "            top_n_movie_ids.append(movie_id)\n",
    "            movie_index = movies_df[movies_df.movieId == movie_id].index[0]\n",
    "            top_n_movie_names.append(movies_df.title.values[movie_index])\n",
    "            if len(top_n_movie_ids) == n:\n",
    "                break\n",
    "\n",
    "    return top_n_movie_ids,top_n_movie_names\n",
    "\n",
    "\n",
    "n = 5  \n",
    "top_n_ids ,top_n_movies = recommend_top_n_movies(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb352ef5-8b39-47cc-afe6-d6b750e2cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nBased on your user preference above, we recommend the following top {n} movies for you:\")\n",
    "for i in range(n):\n",
    "    print(f\"{i+1}. {top_n_movies[i]} (ID: {top_n_ids[i]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6df378-7157-4374-bc6a-ed780be73585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
